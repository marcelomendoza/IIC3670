{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3670 NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- flair 0.12\n",
    "- allennlp==0.9.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:46:09,529 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "2023-05-11 09:46:14,060 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "ner_tagger = SequenceTagger.load('ner')\n",
    "pos_tagger = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[6]: \"George Washington was born in Washington\" → [\"George Washington\"/PER, \"Washington\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington was born in Washington')\n",
    "\n",
    "ner_tagger.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington PER\n",
      "Washington LOC\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "  print(entity.text , entity.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George NNP\n",
      "Washington NNP\n",
      "was VBD\n",
      "born VBN\n",
      "in IN\n",
      "Washington NNP\n"
     ]
    }
   ],
   "source": [
    "pos_tagger.predict(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "   print(token.text, token.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"Whitney\"\n",
      "tensor([-8.6821e-02,  9.3834e-04,  9.3298e-02,  ..., -1.4167e-05,\n",
      "         8.4766e-03,  6.6558e-05])\n",
      "Token[1]: \"tiene\"\n",
      "tensor([ 1.7966e-02, -4.1171e-04,  1.8595e-03,  ..., -2.3416e-05,\n",
      "         2.2486e-04,  3.8149e-04])\n",
      "Token[2]: \"una\"\n",
      "tensor([-2.9416e-02,  2.5448e-04,  2.6700e-02,  ..., -6.4758e-06,\n",
      "         9.1020e-04,  6.0708e-05])\n",
      "Token[3]: \"historia\"\n",
      "tensor([ 3.4301e-02,  4.8836e-03,  4.0833e-02,  ..., -1.0331e-05,\n",
      "         1.0874e-02, -4.4025e-03])\n",
      "Token[4]: \"llena\"\n",
      "tensor([-6.9203e-02, -2.8580e-03,  9.7360e-03,  ..., -2.5984e-05,\n",
      "         3.8512e-03, -2.7470e-03])\n",
      "Token[5]: \"de\"\n",
      "tensor([ 3.7302e-02,  4.7254e-04, -3.0727e-03,  ..., -3.0066e-05,\n",
      "         3.3274e-03, -7.5158e-04])\n",
      "Token[6]: \"drama\"\n",
      "tensor([-1.2064e-01,  2.6104e-04,  3.7579e-02,  ..., -2.7386e-05,\n",
      "        -9.2416e-03, -5.6781e-03])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "\n",
    "flair_embedding_forward = FlairEmbeddings('spanish-forward')\n",
    "\n",
    "sentence = Sentence('Whitney tiene una historia llena de drama')\n",
    "\n",
    "flair_embedding_forward.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver más embeddings en: https://flairnlp.github.io/docs/tutorial-embeddings/flair-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"La\"\n",
      "tensor([-1.6193e-02,  1.4907e-03,  1.2598e-02,  ..., -2.3243e-06,\n",
      "         5.4600e-03,  1.7847e-04])\n",
      "Token[1]: \"historia\"\n",
      "tensor([ 1.5450e-01,  2.0388e-03,  3.9008e-02,  ..., -1.1207e-05,\n",
      "         2.8937e-02, -1.5640e-03])\n",
      "Token[2]: \"sin\"\n",
      "tensor([-6.0255e-02,  1.3912e-02,  1.4367e-01,  ..., -2.9156e-05,\n",
      "         7.4421e-04,  1.0845e-02])\n",
      "Token[3]: \"fin\"\n",
      "tensor([ 2.5528e-02,  9.2127e-03,  3.5452e-02,  ..., -6.7441e-05,\n",
      "         7.9362e-02,  6.7573e-04])\n",
      "Token[4]: \"es\"\n",
      "tensor([-8.8894e-03,  2.8105e-03,  4.4454e-04,  ..., -8.8751e-06,\n",
      "         6.1890e-04,  1.3850e-04])\n",
      "Token[5]: \"una\"\n",
      "tensor([-1.9456e-02,  1.2340e-04,  3.7264e-03,  ..., -8.1354e-06,\n",
      "         3.1620e-03, -6.0251e-04])\n",
      "Token[6]: \"pelicula\"\n",
      "tensor([-1.0766e-01, -5.2601e-04,  4.8633e-02,  ..., -7.0584e-06,\n",
      "         2.1830e-02, -1.1417e-03])\n",
      "Token[7]: \"de\"\n",
      "tensor([ 8.0026e-02, -7.6142e-04,  1.2470e-02,  ..., -6.7769e-06,\n",
      "         4.7873e-02, -1.6199e-03])\n",
      "Token[8]: \"los\"\n",
      "tensor([-8.8328e-03,  1.5163e-03,  2.0621e-02,  ..., -3.5582e-05,\n",
      "         2.8466e-02, -6.8294e-05])\n",
      "Token[9]: \"80s\"\n",
      "tensor([ 0.0162,  0.0006,  0.0195,  ..., -0.0001, -0.0375, -0.0011])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('La historia sin fin es una pelicula de los 80s')\n",
    "\n",
    "flair_embedding_forward.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:28:37,727 Reading data from C:\\Users\\marce\\.flair\\datasets\\ner_english_sec_fillings\n",
      "2023-04-12 14:28:37,728 Train: C:\\Users\\marce\\.flair\\datasets\\ner_english_sec_fillings\\FIN5.txt\n",
      "2023-04-12 14:28:37,729 Dev: None\n",
      "2023-04-12 14:28:37,729 Test: C:\\Users\\marce\\.flair\\datasets\\ner_english_sec_fillings\\FIN3.txt\n",
      "Corpus: 1051 train + 117 dev + 305 test sentences\n"
     ]
    }
   ],
   "source": [
    "import flair.datasets\n",
    "\n",
    "corpus = flair.datasets.NER_ENGLISH_SEC_FILLINGS()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver mas corpus en: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_CORPUS_PREPARED.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:28:42,974 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1051it [00:00, 130020.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:28:42,985 Dictionary created for label 'ner' with 4 values: PER (seen 691 times), ORG (seen 219 times), LOC (seen 158 times), MISC (seen 7 times)\n",
      "Dictionary with 4 tags: PER, ORG, LOC, MISC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:28:44,123 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to C:\\Users\\marce\\AppData\\Local\\Temp\\tmpc1tg25dy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 153M/153M [01:13<00:00, 2.19MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:29:57,854 copying C:\\Users\\marce\\AppData\\Local\\Temp\\tmpc1tg25dy to cache at C:\\Users\\marce\\.flair\\embeddings\\glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:29:57,930 removing temp file C:\\Users\\marce\\AppData\\Local\\Temp\\tmpc1tg25dy\n",
      "2023-04-12 14:29:58,592 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to C:\\Users\\marce\\AppData\\Local\\Temp\\tmpl9o4iykk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 20.5M/20.5M [00:16<00:00, 1.34MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:30:15,356 copying C:\\Users\\marce\\AppData\\Local\\Temp\\tmpl9o4iykk to cache at C:\\Users\\marce\\.flair\\embeddings\\glove.gensim\n",
      "2023-04-12 14:30:15,359 removing temp file C:\\Users\\marce\\AppData\\Local\\Temp\\tmpl9o4iykk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:30:17,971 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to C:\\Users\\marce\\AppData\\Local\\Temp\\tmplnxin_lk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 69.7M/69.7M [00:42<00:00, 1.74MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:31:00,643 copying C:\\Users\\marce\\AppData\\Local\\Temp\\tmplnxin_lk to cache at C:\\Users\\marce\\.flair\\embeddings\\news-backward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:31:00,660 removing temp file C:\\Users\\marce\\AppData\\Local\\Temp\\tmplnxin_lk\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "label_type = 'ner'\n",
    "\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type, add_unk=False)\n",
    "print(label_dict)\n",
    "\n",
    "embedding_types = [\n",
    "    WordEmbeddings('glove'),\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:31:00,806 SequenceTagger predicts: Dictionary with 17 tags: O, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver documentación en: https://github.com/flairNLP/flair/blob/master/flair/models/sequence_tagger_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:31:26,676 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,677 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2023-04-12 14:31:26,678 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,679 Corpus: \"Corpus: 1051 train + 117 dev + 305 test sentences\"\n",
      "2023-04-12 14:31:26,680 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,681 Parameters:\n",
      "2023-04-12 14:31:26,681  - learning_rate: \"0.100000\"\n",
      "2023-04-12 14:31:26,681  - mini_batch_size: \"4\"\n",
      "2023-04-12 14:31:26,681  - patience: \"3\"\n",
      "2023-04-12 14:31:26,681  - anneal_factor: \"0.5\"\n",
      "2023-04-12 14:31:26,681  - max_epochs: \"10\"\n",
      "2023-04-12 14:31:26,681  - shuffle: \"True\"\n",
      "2023-04-12 14:31:26,681  - train_with_dev: \"False\"\n",
      "2023-04-12 14:31:26,681  - batch_growth_annealing: \"False\"\n",
      "2023-04-12 14:31:26,681 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,681 Model training base path: \"resources\\taggers\\sota-ner-flair\"\n",
      "2023-04-12 14:31:26,681 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,681 Device: cpu\n",
      "2023-04-12 14:31:26,681 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:31:26,681 Embeddings storage mode: none\n",
      "2023-04-12 14:31:26,681 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:32:16,610 epoch 1 - iter 26/263 - loss 0.50089076 - time (sec): 49.93 - samples/sec: 58.32 - lr: 0.009886\n",
      "2023-04-12 14:33:12,090 epoch 1 - iter 52/263 - loss 0.29429641 - time (sec): 105.41 - samples/sec: 58.33 - lr: 0.019772\n",
      "2023-04-12 14:34:06,996 epoch 1 - iter 78/263 - loss 0.34257468 - time (sec): 160.31 - samples/sec: 58.25 - lr: 0.029658\n",
      "2023-04-12 14:35:05,244 epoch 1 - iter 104/263 - loss 0.34869468 - time (sec): 218.56 - samples/sec: 58.89 - lr: 0.039544\n",
      "2023-04-12 14:35:48,135 epoch 1 - iter 130/263 - loss 0.32672256 - time (sec): 261.45 - samples/sec: 58.29 - lr: 0.049430\n",
      "2023-04-12 14:36:35,555 epoch 1 - iter 156/263 - loss 0.34064661 - time (sec): 308.87 - samples/sec: 58.19 - lr: 0.059316\n",
      "2023-04-12 14:37:59,930 epoch 1 - iter 182/263 - loss 0.32018545 - time (sec): 393.25 - samples/sec: 58.18 - lr: 0.069202\n",
      "2023-04-12 14:39:04,223 epoch 1 - iter 208/263 - loss 0.38986037 - time (sec): 457.54 - samples/sec: 58.56 - lr: 0.079087\n",
      "2023-04-12 14:40:27,211 epoch 1 - iter 234/263 - loss 0.45385541 - time (sec): 540.53 - samples/sec: 59.11 - lr: 0.088973\n",
      "2023-04-12 14:41:36,839 epoch 1 - iter 260/263 - loss 0.49662355 - time (sec): 610.16 - samples/sec: 59.01 - lr: 0.098859\n",
      "2023-04-12 14:41:40,758 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:41:40,773 EPOCH 1 done: loss 0.5054 - lr 0.098859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:42:27,281 Evaluating as a multi-label problem: False\n",
      "2023-04-12 14:42:27,287 DEV : loss 1.5489709377288818 - f1-score (micro avg)  0.098\n",
      "2023-04-12 14:42:27,287 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:43:18,945 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:43:18,945 Exiting from training early.\n",
      "2023-04-12 14:43:18,945 Saving model ...\n",
      "2023-04-12 14:43:19,730 Done.\n",
      "2023-04-12 14:43:19,746 ----------------------------------------------------------------------------------------------------\n",
      "2023-04-12 14:43:19,747 Testing using last state of model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 77/77 [02:14<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 14:45:34,450 Evaluating as a multi-label problem: False\n",
      "2023-04-12 14:45:34,457 0.6782\t0.6164\t0.6458\t0.4769\n",
      "2023-04-12 14:45:34,458 \n",
      "Results:\n",
      "- F-score (micro) 0.6458\n",
      "- F-score (macro) 0.1941\n",
      "- Accuracy 0.4769\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER     0.6782    0.9074    0.7762       216\n",
      "         ORG     0.0000    0.0000    0.0000        56\n",
      "         LOC     0.0000    0.0000    0.0000        39\n",
      "        MISC     0.0000    0.0000    0.0000         7\n",
      "\n",
      "   micro avg     0.6782    0.6164    0.6458       318\n",
      "   macro avg     0.1696    0.2269    0.1941       318\n",
      "weighted avg     0.4607    0.6164    0.5273       318\n",
      "\n",
      "2023-04-12 14:45:34,458 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.645799011532125,\n",
       " 'dev_score_history': [0.09795191451469279],\n",
       " 'train_loss_history': [0.5053509612491174],\n",
       " 'dev_loss_history': [1.5489709377288818]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fine_tune('resources/taggers/sota-ner-flair',\n",
    "                  learning_rate=0.1,\n",
    "                  mini_batch_size=4,\n",
    "                  mini_batch_chunk_size=1,\n",
    "                  max_epochs=10,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
