{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3670 NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librer√≠as, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- spacy 3.5.1\n",
    "- sklearn \n",
    "- keras 2.9.0\n",
    "- tensorflow 2.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_30276\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-md==3.5.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.5.0/es_core_news_md-3.5.0-py3-none-any.whl (42.3 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from es-core-news-md==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.23.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marce\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-md==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\marce\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "sp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = sp(\"Paredes bate el record de Chamaco Valdes y deja a la U en zona de descenso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paredes        PROPN          \n",
      "bate           VERB           \n",
      "el             DET            \n",
      "record         NOUN           \n",
      "de             ADP            \n",
      "Chamaco        PROPN          \n",
      "Valdes         PROPN          \n",
      "y              CCONJ          \n",
      "deja           VERB           \n",
      "a              ADP            \n",
      "la             DET            \n",
      "U              PROPN          \n",
      "en             ADP            \n",
      "zona           NOUN           \n",
      "de             ADP            \n",
      "descenso       NOUN           \n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(str(word.text).ljust(15) + str(word.pos_).ljust(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paredes - PER - Named person or family.\n",
      "Chamaco Valdes - PER - Named person or family.\n",
      "U - MISC - Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paredes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " bate el record de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chamaco Valdes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y deja a la \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " en zona de descenso</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a POS tagger from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.' 'Vinken' 'is' 'chairman' 'of' 'Elsevier' 'N.V.' ',' 'the' 'Dutch'\n",
      " 'publishing' 'group' '.']\n",
      "['NNP' 'NNP' 'VBZ' 'NN' 'IN' 'NNP' 'NNP' ',' 'DT' 'NNP' 'VBG' 'NN' '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    " \n",
    "print(sentences[1])\n",
    "print(sentence_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "(train_sentences, test_sentences,  train_tags,  test_tags) = train_test_split(sentences, sentence_tags, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    " \n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    " \n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0   # The special value used to padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-LRB-', 'VBN', 'NNP', 'LS', '.', 'CC', 'RBS', 'FW', 'VBP', 'IN', 'VBD', '``', '-NONE-', 'JJR', 'MD', 'NN', 'CD', 'RP', \"''\", 'RB', 'EX', 'WDT', 'UH', '$', 'JJ', 'PRP$', 'JJS', 'VBG', 'NNPS', 'WP', 'SYM', 'POS', 'TO', 'PRP', 'PDT', 'WRB', ':', 'NNS', 'VB', 'DT', 'VBZ', '-RRB-', '#', 'WP$', 'RBR', ','}\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6169, 842, 4763, 8620, 7926, 4746, 179, 9831, 6765, 6231, 1530, 4679]\n",
      "[2972, 3889, 9838, 3984, 5397, 1, 6646, 740, 2116, 9394, 5447, 4250, 9838, 740, 1, 8218, 473, 2834, 1125, 5746, 740, 2485, 6244, 9831, 1271, 5347, 4679]\n",
      "[3, 3, 32, 16, 38, 11, 3, 10, 40, 3, 16, 5]\n",
      "[20, 20, 46, 36, 34, 11, 10, 40, 16, 17, 38, 25, 46, 40, 25, 38, 11, 2, 37, 10, 40, 25, 16, 10, 17, 38, 5]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    " \n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    " \n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    " \n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "for s in test_tags:\n",
    "    test_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6480  8582  3071   921  9081  6035  5660  7165  6418  8396  3179  4418\n",
      "  4681  8396  9323 10389  3092   395  8396  3402  1142  5635  4047  3813\n",
      "  8505     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0]\n",
      "[ 7312  5410    83     1  4162  8396  2287 10003  6556  6861  7171     1\n",
      "  3250     1  8505     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0]\n",
      "[45 38 38 41 33 30 30 24 46 45 37 43 33 45  5 43 24 18 45 38 34  9 19  1\n",
      " 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[ 2 24 34 24 33 45 30 30 30 30 33  5 35  5 16  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 271, 128)          1339008   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 271, 512)         788480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 271, 47)          24111     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 271, 47)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,151,599\n",
      "Trainable params: 2,151,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy', ignore_class_accuracy(0)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "23/23 [==============================] - 30s 1s/step - loss: 1.0980 - accuracy: 0.8647 - ignore_accuracy: 0.0315 - val_loss: 0.3514 - val_accuracy: 0.9022 - val_ignore_accuracy: 0.1946\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.3223 - accuracy: 0.9107 - ignore_accuracy: 0.1313 - val_loss: 0.3217 - val_accuracy: 0.9096 - val_ignore_accuracy: 0.1305\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.3051 - accuracy: 0.9161 - ignore_accuracy: 0.1335 - val_loss: 0.3097 - val_accuracy: 0.9150 - val_ignore_accuracy: 0.1386\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2942 - accuracy: 0.9177 - ignore_accuracy: 0.1347 - val_loss: 0.2996 - val_accuracy: 0.9153 - val_ignore_accuracy: 0.1421\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2840 - accuracy: 0.9191 - ignore_accuracy: 0.1487 - val_loss: 0.2900 - val_accuracy: 0.9172 - val_ignore_accuracy: 0.1597\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2764 - accuracy: 0.9217 - ignore_accuracy: 0.1736 - val_loss: 0.2831 - val_accuracy: 0.9195 - val_ignore_accuracy: 0.1807\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2702 - accuracy: 0.9240 - ignore_accuracy: 0.1946 - val_loss: 0.2767 - val_accuracy: 0.9234 - val_ignore_accuracy: 0.2191\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2638 - accuracy: 0.9277 - ignore_accuracy: 0.2361 - val_loss: 0.2690 - val_accuracy: 0.9286 - val_ignore_accuracy: 0.2736\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.2537 - accuracy: 0.9351 - ignore_accuracy: 0.3156 - val_loss: 0.2553 - val_accuracy: 0.9373 - val_ignore_accuracy: 0.3614\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2361 - accuracy: 0.9424 - ignore_accuracy: 0.3931 - val_loss: 0.2335 - val_accuracy: 0.9435 - val_ignore_accuracy: 0.4261\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.2099 - accuracy: 0.9476 - ignore_accuracy: 0.4450 - val_loss: 0.2036 - val_accuracy: 0.9465 - val_ignore_accuracy: 0.4561\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.1803 - accuracy: 0.9524 - ignore_accuracy: 0.4965 - val_loss: 0.1753 - val_accuracy: 0.9520 - val_ignore_accuracy: 0.5129\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.1527 - accuracy: 0.9576 - ignore_accuracy: 0.5534 - val_loss: 0.1504 - val_accuracy: 0.9591 - val_ignore_accuracy: 0.5840\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.1285 - accuracy: 0.9655 - ignore_accuracy: 0.6386 - val_loss: 0.1266 - val_accuracy: 0.9665 - val_ignore_accuracy: 0.6599\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.1063 - accuracy: 0.9729 - ignore_accuracy: 0.7130 - val_loss: 0.1074 - val_accuracy: 0.9731 - val_ignore_accuracy: 0.7274\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 23s 984ms/step - loss: 0.0874 - accuracy: 0.9792 - ignore_accuracy: 0.7807 - val_loss: 0.0922 - val_accuracy: 0.9773 - val_ignore_accuracy: 0.7696\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 22s 928ms/step - loss: 0.0716 - accuracy: 0.9840 - ignore_accuracy: 0.8310 - val_loss: 0.0783 - val_accuracy: 0.9824 - val_ignore_accuracy: 0.8216\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 21s 906ms/step - loss: 0.0579 - accuracy: 0.9881 - ignore_accuracy: 0.8753 - val_loss: 0.0678 - val_accuracy: 0.9850 - val_ignore_accuracy: 0.8485\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0468 - accuracy: 0.9909 - ignore_accuracy: 0.9047 - val_loss: 0.0588 - val_accuracy: 0.9869 - val_ignore_accuracy: 0.8672\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.0380 - accuracy: 0.9928 - ignore_accuracy: 0.9238 - val_loss: 0.0526 - val_accuracy: 0.9882 - val_ignore_accuracy: 0.8803\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0313 - accuracy: 0.9939 - ignore_accuracy: 0.9369 - val_loss: 0.0479 - val_accuracy: 0.9890 - val_ignore_accuracy: 0.8884\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0262 - accuracy: 0.9949 - ignore_accuracy: 0.9462 - val_loss: 0.0443 - val_accuracy: 0.9896 - val_ignore_accuracy: 0.8943\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0223 - accuracy: 0.9956 - ignore_accuracy: 0.9539 - val_loss: 0.0417 - val_accuracy: 0.9899 - val_ignore_accuracy: 0.8979\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0193 - accuracy: 0.9961 - ignore_accuracy: 0.9589 - val_loss: 0.0398 - val_accuracy: 0.9902 - val_ignore_accuracy: 0.9000\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0170 - accuracy: 0.9965 - ignore_accuracy: 0.9639 - val_loss: 0.0389 - val_accuracy: 0.9904 - val_ignore_accuracy: 0.9026\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 25s 1s/step - loss: 0.0151 - accuracy: 0.9969 - ignore_accuracy: 0.9667 - val_loss: 0.0375 - val_accuracy: 0.9906 - val_ignore_accuracy: 0.9047\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0136 - accuracy: 0.9972 - ignore_accuracy: 0.9702 - val_loss: 0.0368 - val_accuracy: 0.9908 - val_ignore_accuracy: 0.9064\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0124 - accuracy: 0.9973 - ignore_accuracy: 0.9715 - val_loss: 0.0365 - val_accuracy: 0.9910 - val_ignore_accuracy: 0.9083\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0113 - accuracy: 0.9977 - ignore_accuracy: 0.9754 - val_loss: 0.0356 - val_accuracy: 0.9911 - val_ignore_accuracy: 0.9092\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.0103 - accuracy: 0.9978 - ignore_accuracy: 0.9766 - val_loss: 0.0359 - val_accuracy: 0.9910 - val_ignore_accuracy: 0.9086\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.0096 - accuracy: 0.9980 - ignore_accuracy: 0.9790 - val_loss: 0.0352 - val_accuracy: 0.9911 - val_ignore_accuracy: 0.9096\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0089 - accuracy: 0.9981 - ignore_accuracy: 0.9803 - val_loss: 0.0352 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9110\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0083 - accuracy: 0.9983 - ignore_accuracy: 0.9813 - val_loss: 0.0350 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9112\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.0077 - accuracy: 0.9984 - ignore_accuracy: 0.9835 - val_loss: 0.0348 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9119\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0072 - accuracy: 0.9985 - ignore_accuracy: 0.9837 - val_loss: 0.0348 - val_accuracy: 0.9914 - val_ignore_accuracy: 0.9124\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0068 - accuracy: 0.9986 - ignore_accuracy: 0.9852 - val_loss: 0.0357 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9114\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0064 - accuracy: 0.9987 - ignore_accuracy: 0.9863 - val_loss: 0.0355 - val_accuracy: 0.9913 - val_ignore_accuracy: 0.9121\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 26s 1s/step - loss: 0.0059 - accuracy: 0.9988 - ignore_accuracy: 0.9864 - val_loss: 0.0357 - val_accuracy: 0.9914 - val_ignore_accuracy: 0.9126\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 25s 1s/step - loss: 0.0056 - accuracy: 0.9988 - ignore_accuracy: 0.9879 - val_loss: 0.0357 - val_accuracy: 0.9914 - val_ignore_accuracy: 0.9125\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 27s 1s/step - loss: 0.0053 - accuracy: 0.9989 - ignore_accuracy: 0.9884 - val_loss: 0.0357 - val_accuracy: 0.9914 - val_ignore_accuracy: 0.9129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8ac184640>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 174ms/step - loss: 0.0328 - accuracy: 0.9917 - ignore_accuracy: 0.9147\n",
      "accuracy: 99.17287826538086\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 610ms/step\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\"running is very important for me\".split(), \"I was running every day for a month\".split()]\n",
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    " \n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "predictions = model.predict(test_samples_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VBG', 'VBZ', 'RB', 'JJ', 'IN', 'PRP']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})[0][:len(test_samples[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VBD', 'VBG', 'DT', 'NN', 'IN', 'DT', 'NN']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})[1][:len(test_samples[1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
