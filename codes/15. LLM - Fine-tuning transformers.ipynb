{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3670 NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16faf1e9ca844f5292227f0a61b31db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.29.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA RTX A5000\n",
      "11.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface incluye un helper para debug data. Más utilidades en \n",
    "https://huggingface.co/docs/huggingface_hub/main/en/package_reference/utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"language_modeling_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a DistilGPT2 con Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a descargar wikitext, ver más datasets en \n",
    "\n",
    "https://huggingface.co/docs/datasets/loading\n",
    "\n",
    "Archivos raw descargados desde\n",
    "\n",
    "https://cosmo.zip/pub/datasets/wikitext-2-raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-87494e0b3c88bd8d\n",
      "Reusing dataset text (/home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f8e49d47274985803bf57226d50097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "datasets = load_dataset('text', data_files={'train': 'wikitext/wiki.train.raw', \n",
    "                                           'validation': 'wikitext/wiki.valid.raw', \n",
    "                                           'test': 'wikitext/wiki.test.raw'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a ver alguno ejemplos del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The music video was co @-@ directed by Ray Kay and Beyoncé for the B 'Day Anthology Video Album , which was released the same month : it was one of eight videos shot in two weeks for the album . The choreography was done by Danielle Polanco and Jonte ' Moaning , who used a 1980 ’ s retro set . Beyoncé explained the concept of the video at MTV : \" It 's probably the most flamboyant video , and the metallic dresses are so beautiful , they added so much color . I had to do a video for this song . Everyone wanted to know what a ' freakum dress ' was , and you can 't really explain it , you have to see it . Everyone has their own version , so we had so many women — of different races , sizes , shapes , ages — because we all have those dresses we pull out when we need to shut it down . \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= = Other important information = =</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York State Route 368 ( NY 368 ) was a state highway in Onondaga County , New York , in the United States . It was one of the shortest routes in the county , extending for only 1 @.@ 69 miles ( 2 @.@ 72 km ) between NY 321 and NY 5 in the town of Elbridge . NY 368 was known as Halfway Road for the hamlet it served near its midpoint . The route was assigned in the 1930s and removed in 1980 as part of a highway maintenance swap between the state of New York and Onondaga County .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sonate de concert , Op. 47 , for cello and piano – played by Steven Osborne ( piano ) and Alban Gebhart ( cello ) . Recorded 2008 . Hyperion CDA67624 ( 2008 ) .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>After his tour , Dylan returned to New York , but the pressures increased . ABC Television had paid an advance for a TV show . His publisher , Macmillan , was demanding a manuscript of the poem / novel Tarantula . Manager Albert Grossman had scheduled a concert tour for the latter part of the year .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The burning in 1789 of Christian Murphy , for coining , received practically no attention from the newspapers ( perhaps owing to practical limitations on how much news they could publish across only four pages ) , but it may have been enacted by Sir Benjamin Hammett , a former sheriff of London . Hammett was also an MP , and in 1790 he introduced to Parliament a Bill for Altering the Sentence of Burning Women . He denounced the punishment as \" the savage remains of Norman policy \" which \" disgraced our statutes \" , as \" the practice did the common law \" . He also highlighted how a sheriff who refused to carry out the sentence was liable to prosecution . William Wilberforce and Hammett were not the first men to attempt to end the burning of women . Almost 140 years earlier , during the Interregnum , a group of lawyers and laymen known as the Hale Commission ( after its chairman Matthew Hale ) , was tasked by the House of Commons to take \" into consideration what inconveniences there are in the law \" . Among the proposed reforms was the replacement of burning at the stake with hanging , but , mainly through the objections of various interested parties , none of the commission 's proposals made it into law during the Rump Parliament . Hammett was confident though . He believed that public opinion was on his side and that \" the House would go with him in the cause of humanity \" . The change in execution venues , from Tyburn to Newgate , also attracted criticism . Following Phoebe Harris 's burning in 1786 , as well as questioning the inequality of English law The Times complained about the location of the punishment and its effect on locals :</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "    \n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a trabajar con un modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrapper:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "        return self.tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo muy relevante de transformers es el tokenizer que vamos a usar, el cual debe ser consistente con el usado cuanso se entrenó el LLM. Usamos AutoTokenizer para implementar esta parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El wrapper es un tokenizer que usa el autotokenizer, el cual a su vez es consistente con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_wrapper = TokenizerWrapper(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora tokenizamos los datasets de wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-ced325a633499540.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-268a3d3b2db002d2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-96151d5b1878ba97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-d576064cbfd83386.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-083efea1cc6473cd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-d8939ee389a73804.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-550699ce83e95a6c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-2f0736d8c8cc74f3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-4aafa3555bc66335.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-f7ea51f83a2e377c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-08ea5c52e5c8e6e1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-4b8933684b4e8df8.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenizer_wrapper.tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fíjese que la máscara de atención viene en 1. Esto es atención global. ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [796, 569, 18354, 7496, 17740, 6711, 796, 220],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group_texts construye los batches para hacer el fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    block_size = 128\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usamos la función map para aplicar group_texts al dataset tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-8f042679fae47b41.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-5ac7876e06f63ef2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-94ebbaa40b96b3c4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-41b54c84223caa04.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-824c1796f712e859.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-49c8e4266b17689f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e8eb833e0fdfb2a1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e99d559adf5b1607.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-90c977bbde88d257.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e60c5dffc18f00e0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e10aeb854d73896b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-1ca19f18869eb84e.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un decoder nos permite devolvernos al espacio del texto (desde los IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \".  The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Oz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a usar AutoModelForCausalLM para cargar el LLM. ¿Por qué ahora usamos causalidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y ahora usamos el trainer de transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/.local/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/marcelo/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/marcelo/Dropbox/Codes_STGO/IIC-3670/Codes-2024/wandb/run-20240513_191030-kcq0rfw3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mendoza-lab/huggingface/runs/kcq0rfw3' target=\"_blank\">polished-water-1</a></strong> to <a href='https://wandb.ai/mendoza-lab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mendoza-lab/huggingface' target=\"_blank\">https://wandb.ai/mendoza-lab/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mendoza-lab/huggingface/runs/kcq0rfw3' target=\"_blank\">https://wandb.ai/mendoza-lab/huggingface/runs/kcq0rfw3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6969' max='6969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6969/6969 08:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.789500</td>\n",
       "      <td>3.687077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.673800</td>\n",
       "      <td>3.665438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.613500</td>\n",
       "      <td>3.663053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6969, training_loss=3.7129432611442192, metrics={'train_runtime': 551.6615, 'train_samples_per_second': 101.057, 'train_steps_per_second': 12.633, 'total_flos': 1820879068594176.0, 'train_loss': 3.7129432611442192, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos los pesos del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilgpt2-finetuned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para luego poder reusarlos. Yo hice fine tuning usando next token prediction, que es reentrenar el base sobre un dataset nuevo (wikitext). Generalmente se hace fine tuning para una downstream task, por ejemplo, clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type gpt2 to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilgpt2-finetuned.h5 were not used when initializing DistilBertModel: ['transformer.h.4.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.5.attn.masked_bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.0.attn.bias', 'transformer.h.3.ln_2.bias', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.0.ln_1.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.2.attn.masked_bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.3.attn.masked_bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.4.ln_1.weight', 'transformer.h.1.attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.1.attn.masked_bias', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.2.ln_2.weight', 'transformer.h.3.attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.wpe.weight', 'transformer.h.2.attn.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.wte.weight', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.5.attn.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.1.ln_1.bias', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.bias', 'transformer.h.1.ln_2.bias', 'transformer.h.5.ln_2.bias', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.ln_f.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.5.ln_2.weight', 'lm_head.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.2.mlp.c_proj.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertModel were not initialized from the model checkpoint at distilgpt2-finetuned.h5 and are newly initialized: ['transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.3.output_layer_norm.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.0.attention.q_lin.weight', 'embeddings.position_embeddings.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin1.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.5.ffn.lin1.bias', 'embeddings.LayerNorm.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.4.attention.q_lin.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig, DistilBertModel\n",
    "\n",
    "model = DistilBertModel.from_pretrained(\"distilgpt2-finetuned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a hacer lo mismo pero sobre un transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilroberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386a75ed252444b791ef29995687359c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer_config.json', max=25.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd45609c9e34493bcada00d80e9321a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading config.json', max=480.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc27fc5d18349cdbda4a9f94e377a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading vocab.json', max=898823.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db109d57750f47db82727650f4034f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading merges.txt', max=456318.0, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd52d712b8b1402ebb2e6ff40147900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer.json', max=1355863.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-268a3d3b2db002d2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-ced325a633499540.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-96151d5b1878ba97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-d576064cbfd83386.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-083efea1cc6473cd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-d8939ee389a73804.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-550699ce83e95a6c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-2f0736d8c8cc74f3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-f7ea51f83a2e377c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-4aafa3555bc66335.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-08ea5c52e5c8e6e1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-4b8933684b4e8df8.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenized_datasets = datasets.map(tokenizer_wrapper.tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-8f042679fae47b41.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-5ac7876e06f63ef2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-94ebbaa40b96b3c4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-41b54c84223caa04.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-824c1796f712e859.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-49c8e4266b17689f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e8eb833e0fdfb2a1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e99d559adf5b1607.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-90c977bbde88d257.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e60c5dffc18f00e0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-e10aeb854d73896b.arrow\n",
      "Loading cached processed dataset at /home/marcelo/.cache/huggingface/datasets/text/default-87494e0b3c88bd8d/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8/cache-1ca19f18869eb84e.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y usando esos pesos, inicializo un MaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc870c314e2e4c7fb3ffda7102459980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading pytorch_model.bin', max=331070498.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y le hago fine tuning usando wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para hacer MLM uso dataCollator, el cual crea las máscaras on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/.local/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6969' max='6969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6969/6969 08:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.922500</td>\n",
       "      <td>5.805290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.660300</td>\n",
       "      <td>5.615483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.563200</td>\n",
       "      <td>5.558799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6969, training_loss=5.838468449001829, metrics={'train_runtime': 525.9937, 'train_samples_per_second': 105.988, 'train_steps_per_second': 13.249, 'total_flos': 1848383273924352.0, 'train_loss': 5.838468449001829, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilroberta-finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-finetuned.h5 were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at distilroberta-finetuned.h5 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "model = RobertaModel.from_pretrained(\"distilroberta-finetuned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El tokenizer es específico para RoBERTa. Uso ese para leer el modelo finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0036,  0.1218,  0.0173,  ..., -0.1361, -0.1020, -0.0761],\n",
       "         [-0.0740,  0.1353,  0.0308,  ..., -0.2017, -0.0584, -0.0205],\n",
       "         [ 0.0425,  0.1917, -0.0249,  ..., -0.5382,  0.0393,  0.0334],\n",
       "         ...,\n",
       "         [ 0.0076,  0.0704, -0.0665,  ...,  0.2193,  0.2206, -0.0945],\n",
       "         [-0.0229,  0.1350, -0.0236,  ..., -0.1743, -0.1021, -0.0869],\n",
       "         [ 0.0490,  0.0871,  0.0052,  ..., -0.0363, -0.0795, -0.0254]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.9930e-01,  1.3029e-01,  2.3328e-01,  3.5544e-01,  2.4282e-02,\n",
       "         -2.0471e-01,  3.7913e-01, -1.7386e-03,  1.5449e-02, -1.2459e-02,\n",
       "         -1.2383e-01,  2.1325e-01, -6.7104e-01,  4.4308e-01,  2.9050e-01,\n",
       "          1.1843e-01,  3.5523e-01,  3.2490e-01,  4.1214e-01, -9.5686e-03,\n",
       "          2.1462e-01,  1.0005e-01, -3.2149e-01,  2.8485e-01,  8.0962e-02,\n",
       "          5.6077e-01,  1.7002e-01,  1.4226e-01, -2.3036e-01, -2.1661e-01,\n",
       "         -2.8509e-01,  3.2705e-01, -6.9486e-02,  2.2162e-01,  1.2637e-01,\n",
       "          6.8274e-01,  1.2995e-01, -1.2741e-01, -1.7620e-01,  3.4737e-01,\n",
       "         -2.0419e-01, -5.8088e-01, -3.4564e-01, -2.1113e-01,  8.7930e-02,\n",
       "          2.9946e-01, -1.2424e-01,  1.8447e-01,  1.8124e-02,  8.9027e-02,\n",
       "         -7.3901e-01, -1.4831e-01,  1.1549e-01,  2.9866e-01,  2.3177e-02,\n",
       "         -4.9929e-03,  1.3585e-01, -2.2032e-01, -2.6024e-01, -4.0367e-01,\n",
       "          1.2369e-01,  3.6919e-01,  5.7680e-01, -3.0109e-01, -7.3621e-02,\n",
       "         -2.1289e-01,  5.0610e-01, -2.9609e-01,  4.4705e-01,  1.1814e-01,\n",
       "          2.0013e-01,  3.9763e-01,  2.8341e-01,  2.7656e-01,  5.9760e-02,\n",
       "         -1.5019e-02,  2.9286e-01,  4.9220e-02,  3.6101e-01,  3.2316e-01,\n",
       "         -3.1875e-01, -1.4014e-01,  8.8617e-02,  2.7262e-01, -5.4187e-01,\n",
       "         -4.2767e-01, -1.2020e-01,  3.5011e-02, -3.5715e-01, -1.5097e-01,\n",
       "         -3.7380e-01,  2.1917e-01,  7.2304e-02,  1.5449e-01,  1.3025e-01,\n",
       "          4.0886e-01, -5.7103e-02, -2.7227e-01,  2.4934e-01, -1.3767e-01,\n",
       "         -3.3954e-01,  4.5753e-01, -2.5730e-01,  3.1505e-01, -2.5613e-01,\n",
       "         -3.0941e-01, -3.5916e-01, -1.0693e-01, -6.5089e-02,  2.6901e-02,\n",
       "         -2.9790e-01,  1.9342e-01,  9.7613e-02, -5.5945e-01, -7.3598e-02,\n",
       "         -1.9735e-01, -9.4720e-02, -1.4109e-01, -1.8615e-01, -2.0264e-01,\n",
       "         -1.1247e-01,  9.0774e-02,  2.9314e-01, -2.7963e-01, -4.0270e-01,\n",
       "         -2.3219e-01,  4.9246e-01, -1.5047e-01, -1.2406e-01,  4.5006e-01,\n",
       "          6.2939e-02, -1.2499e-01, -2.1394e-01,  5.6056e-02,  2.0728e-01,\n",
       "         -4.6218e-02,  2.3023e-01, -1.6960e-01, -1.0127e-01,  2.9038e-02,\n",
       "          2.1687e-01,  3.5266e-02,  1.5953e-01,  1.7784e-01, -2.5822e-01,\n",
       "          3.0224e-01, -2.7446e-01,  4.4679e-01,  2.0031e-01,  1.6664e-01,\n",
       "          1.9260e-01, -5.6868e-01, -1.3432e-01,  3.3669e-01,  4.3165e-01,\n",
       "          2.2430e-01, -3.1690e-02,  5.3302e-01, -3.4947e-01,  1.0247e-01,\n",
       "          5.5861e-02, -6.4034e-02,  2.2270e-01,  1.1497e-01,  2.8170e-02,\n",
       "          3.6404e-01,  2.9594e-01, -6.6115e-02, -2.3050e-01, -2.5546e-01,\n",
       "         -1.7632e-01, -1.1681e-01,  1.9188e-01, -4.4928e-01, -3.1272e-01,\n",
       "         -3.0814e-01, -1.0342e-01, -6.0953e-01, -1.5513e-01,  4.1170e-01,\n",
       "         -3.8122e-02, -1.2847e-03,  2.5196e-01, -2.7812e-01, -2.3030e-01,\n",
       "          2.1798e-01, -1.6327e-01,  1.6211e-01, -7.2834e-02, -2.6004e-02,\n",
       "          3.9338e-02, -5.0716e-02, -9.7827e-03,  4.5205e-01,  1.4122e-01,\n",
       "          1.5592e-01, -4.7480e-01, -2.3288e-03,  3.8447e-01,  1.5110e-01,\n",
       "         -3.0466e-01,  5.7522e-02,  1.4311e-01, -3.3950e-01,  3.4707e-01,\n",
       "         -2.1124e-01, -8.4636e-02,  5.0005e-02, -1.9569e-03,  3.5626e-01,\n",
       "         -2.4198e-01,  1.6324e-01,  5.0113e-01, -4.0096e-01, -3.9275e-01,\n",
       "         -5.0763e-01,  4.3213e-01,  2.9195e-01,  4.2900e-01, -6.0356e-01,\n",
       "          2.3358e-01,  2.1943e-01, -2.0354e-01, -1.8242e-01,  3.2951e-01,\n",
       "         -1.9446e-01,  5.1869e-02,  1.0286e-01, -1.8032e-01, -6.0942e-01,\n",
       "         -3.7286e-01,  2.1271e-01, -3.2135e-01,  6.2930e-01, -3.4286e-01,\n",
       "          3.2284e-01, -1.0142e-01,  1.5363e-02, -4.2841e-01, -6.8850e-02,\n",
       "          4.3005e-01, -5.9733e-02, -2.4616e-01, -1.5192e-02,  1.0868e-01,\n",
       "         -3.1838e-02, -2.1804e-02, -2.1174e-01, -3.4117e-01, -6.7429e-02,\n",
       "          2.8967e-01,  1.0923e-01,  6.8906e-03,  5.3531e-01, -2.7988e-01,\n",
       "          5.9120e-02,  5.7574e-03, -3.8663e-01,  3.9935e-01,  1.1696e-01,\n",
       "          3.5542e-01, -6.7988e-03, -4.2074e-01, -2.4792e-01,  3.1730e-01,\n",
       "          1.6628e-01,  1.2902e-01, -3.1159e-01,  1.0078e-02, -1.2129e-01,\n",
       "         -1.3939e-02,  9.6235e-02, -4.1947e-01,  1.8076e-01, -1.2310e-01,\n",
       "         -3.3393e-01,  3.6861e-01, -1.3699e-01,  6.5515e-01, -1.1145e-01,\n",
       "         -1.0482e-01,  9.5287e-02, -2.2486e-01,  1.7398e-02,  2.2817e-02,\n",
       "         -1.9241e-02,  1.0615e-01,  2.6015e-01,  1.5219e-02,  4.1172e-03,\n",
       "          4.1426e-01, -2.6738e-01,  3.2234e-01,  4.8889e-01, -8.6070e-02,\n",
       "          1.7423e-01,  2.9390e-01,  3.8756e-01, -5.7971e-01, -3.5745e-01,\n",
       "          3.8355e-01, -3.5689e-01,  2.7572e-01,  8.6355e-02, -5.3615e-01,\n",
       "          3.7058e-01,  3.4823e-01,  2.5929e-01,  2.4097e-01,  4.2933e-01,\n",
       "         -2.3913e-01,  2.3478e-01,  1.1857e-02,  7.1184e-01,  4.3850e-01,\n",
       "          2.7936e-01,  1.5628e-01, -1.4352e-01,  1.5355e-01,  1.4395e-01,\n",
       "         -1.2666e-01,  5.4516e-01,  4.6176e-01,  2.8982e-01, -6.0591e-02,\n",
       "         -1.3146e-01,  7.2015e-01, -6.4449e-01,  1.6966e-01,  2.8848e-01,\n",
       "          4.6887e-01,  7.5169e-02,  3.5204e-01, -3.3206e-01, -4.6867e-02,\n",
       "         -9.0423e-02,  3.8153e-01, -5.2731e-01,  3.8099e-01,  1.8385e-01,\n",
       "         -1.6313e-01, -4.6327e-02, -3.1787e-01,  1.6632e-01, -3.0056e-01,\n",
       "          1.7698e-01, -1.8333e-01, -4.8529e-01,  4.7569e-01,  4.2633e-02,\n",
       "          7.3412e-03, -4.2336e-01,  2.2356e-01,  9.9234e-02, -1.2975e-01,\n",
       "          3.3909e-01, -4.4422e-01,  3.7211e-01,  1.5392e-01,  5.4057e-02,\n",
       "         -2.6882e-01, -1.5053e-02,  4.4756e-01,  4.8995e-01,  2.5211e-01,\n",
       "         -1.3255e-01,  3.6503e-01, -8.1871e-02, -4.4467e-01,  2.1259e-01,\n",
       "          3.8720e-01,  4.6148e-01,  1.9984e-01,  6.9161e-02, -1.2189e-02,\n",
       "         -3.0534e-01, -1.7028e-01,  5.2801e-01, -2.1534e-01, -2.1966e-01,\n",
       "         -1.1134e-01,  5.1335e-02,  4.7082e-01,  2.4221e-01,  2.7497e-01,\n",
       "         -3.4268e-02,  4.6594e-01, -1.7391e-01, -9.6526e-02,  4.4607e-01,\n",
       "          1.2322e-01, -5.6354e-01,  2.7883e-01,  2.0863e-01, -3.0264e-01,\n",
       "          1.6642e-01, -5.9802e-02, -2.7871e-01,  1.4760e-02, -4.1216e-01,\n",
       "         -5.5522e-01,  2.0158e-02, -6.2551e-03, -9.1762e-02, -2.5639e-01,\n",
       "         -3.7841e-01, -2.0154e-01,  3.4281e-01,  5.2492e-01, -6.1430e-02,\n",
       "          3.2434e-01, -5.0287e-01,  1.8340e-02, -4.1325e-02, -3.8048e-01,\n",
       "          3.5632e-01,  4.2367e-02, -1.3233e-01,  1.9748e-01,  2.0045e-02,\n",
       "          8.0729e-02,  4.0806e-01, -5.3591e-02, -1.1559e-01,  1.3964e-01,\n",
       "          1.6169e-01,  1.1072e-01, -2.0608e-02, -2.0246e-01, -2.5918e-01,\n",
       "          2.3763e-01, -8.9884e-02, -7.7967e-02,  2.2784e-01, -5.2949e-01,\n",
       "         -3.5085e-01, -1.6119e-01, -3.0393e-02,  5.5445e-02, -1.2631e-01,\n",
       "         -8.7632e-02, -3.4330e-01,  3.6485e-03, -5.0051e-02, -2.2103e-01,\n",
       "          8.5428e-02, -5.6750e-02,  1.1055e-01, -6.3087e-02, -1.0869e-01,\n",
       "          1.0171e-01, -6.3180e-03, -2.3889e-01, -4.1977e-02, -2.2225e-01,\n",
       "          5.5594e-01, -5.0598e-01, -2.9420e-01,  1.3822e-02, -3.1917e-01,\n",
       "          2.7665e-01, -2.8760e-01,  1.5974e-01, -5.9639e-01, -1.5558e-01,\n",
       "          1.4759e-01, -5.8352e-02,  3.7064e-01, -3.6063e-01, -8.0033e-03,\n",
       "         -2.1497e-01,  1.0107e-01,  3.6684e-01,  2.9389e-01, -3.7130e-01,\n",
       "          9.7244e-02,  3.1060e-01,  2.4743e-01, -4.8705e-01, -2.5045e-01,\n",
       "         -8.4910e-02, -6.7133e-02,  4.7748e-01, -3.0179e-01, -1.1732e-01,\n",
       "          1.8186e-01,  5.0525e-02, -3.4052e-01,  3.9829e-01, -6.4456e-01,\n",
       "          3.7280e-01,  1.4090e-01, -1.8874e-01,  1.7477e-01,  1.8331e-01,\n",
       "         -1.9027e-01, -8.6682e-02,  5.8501e-01,  4.4010e-01,  4.3802e-01,\n",
       "          9.6603e-02,  1.1913e-02,  2.3160e-01, -1.5422e-02,  3.6224e-01,\n",
       "         -2.8681e-01, -3.6567e-01, -7.2640e-01,  4.7241e-01, -4.2271e-01,\n",
       "         -1.8246e-02,  6.3588e-01,  1.4061e-01,  1.6986e-01, -2.5937e-01,\n",
       "          3.8524e-01,  2.4335e-01,  4.8734e-02, -4.7497e-02,  4.3780e-01,\n",
       "         -6.4829e-02, -1.2993e-01, -1.2037e-01,  2.6014e-01,  2.5406e-02,\n",
       "          1.1119e-01, -3.0355e-01, -3.2278e-01,  3.2426e-01, -4.4945e-01,\n",
       "          1.3938e-01, -1.0275e-01,  5.7122e-01, -1.0529e-02, -2.1687e-01,\n",
       "         -4.2273e-01, -2.6157e-01, -2.5978e-01, -7.2708e-02,  2.8399e-01,\n",
       "         -4.4684e-01, -1.0313e-01, -1.8990e-01,  2.1106e-01, -7.6664e-03,\n",
       "         -4.5323e-01,  6.4380e-01, -2.3456e-02, -1.9360e-01,  2.8698e-02,\n",
       "         -1.7272e-01, -2.0330e-01,  8.5370e-02,  1.4901e-01,  2.3232e-01,\n",
       "          5.5968e-01, -2.7703e-01,  4.6934e-01, -1.0763e-01,  9.3611e-02,\n",
       "         -9.3154e-02, -4.5981e-01,  3.8233e-01,  6.8968e-01, -1.2819e-01,\n",
       "          3.3589e-01, -9.8680e-02,  1.7969e-01, -6.1163e-02,  8.2547e-02,\n",
       "         -6.9943e-01, -5.1091e-01, -2.7478e-02,  3.0283e-01,  1.8639e-02,\n",
       "         -1.8125e-01,  1.8819e-01,  4.0279e-02,  2.1559e-01, -2.3606e-01,\n",
       "          1.9794e-02,  6.7715e-03, -2.5941e-01, -9.6830e-02, -2.0071e-01,\n",
       "          1.7420e-01,  6.7702e-01,  3.8541e-01,  2.0524e-01,  9.4443e-02,\n",
       "         -8.0339e-02, -5.5379e-01, -4.5724e-02, -4.2800e-03, -4.0182e-02,\n",
       "          1.8680e-01, -7.0245e-02, -5.9723e-01, -6.0739e-02,  1.9075e-02,\n",
       "          2.1540e-01,  4.1662e-01,  2.0721e-01,  3.9807e-01, -6.4493e-01,\n",
       "         -1.6959e-02,  1.5310e-01,  1.5133e-01, -1.1934e-01, -5.5671e-01,\n",
       "         -2.0104e-01,  2.0663e-01,  5.0231e-01, -9.8058e-02, -3.2958e-01,\n",
       "         -1.5799e-01,  5.0631e-01,  2.9119e-01,  5.9935e-01,  1.6782e-01,\n",
       "         -1.7069e-01, -3.3695e-01, -4.9466e-01, -1.6368e-01,  2.4880e-02,\n",
       "          2.8555e-01, -8.2204e-02, -1.3246e-02,  2.7920e-02,  4.9108e-01,\n",
       "          3.1636e-01,  1.2671e-01, -1.7212e-01, -3.5812e-02,  4.3928e-01,\n",
       "          5.3571e-02,  2.0447e-01, -2.7161e-01,  1.0168e-01, -2.1365e-01,\n",
       "         -1.9086e-01, -6.7234e-01, -4.3984e-01, -4.3180e-02,  2.5641e-01,\n",
       "         -9.8054e-02, -3.4436e-01, -3.2889e-02,  1.4233e-01,  1.4581e-01,\n",
       "          4.2499e-01,  7.6668e-02, -5.0205e-01, -1.5837e-02, -3.8087e-01,\n",
       "          5.0232e-01,  7.9136e-02,  4.6442e-01,  4.5437e-01,  1.6952e-01,\n",
       "          1.2415e-01,  8.7244e-03, -2.5501e-04, -1.2704e-01,  1.8886e-01,\n",
       "          4.2533e-01, -1.6970e-01, -4.6982e-02, -6.2973e-02, -9.6287e-02,\n",
       "         -1.3208e-01,  6.5692e-01, -1.4920e-01, -1.3815e-01,  4.7355e-02,\n",
       "          3.8853e-01,  4.5467e-01, -4.3938e-01,  1.9393e-01, -1.7241e-01,\n",
       "          3.5217e-01,  1.2935e-01,  3.9968e-01, -3.0762e-01,  4.3504e-03,\n",
       "         -1.3841e-01, -3.6438e-01,  4.7317e-01, -2.6351e-01, -2.7214e-01,\n",
       "         -2.4876e-01, -1.1772e-01, -3.6455e-01,  5.5591e-01,  2.7879e-01,\n",
       "          1.1300e-01,  4.6163e-02,  6.0658e-01,  1.3824e-03,  2.6925e-01,\n",
       "          2.9786e-01,  3.2504e-01,  5.8543e-01, -1.6359e-01, -4.3120e-01,\n",
       "         -1.6607e-01, -3.2825e-01, -4.9995e-03, -2.7872e-01, -3.4116e-01,\n",
       "         -5.1991e-01,  3.8915e-01, -3.9476e-01, -2.2420e-01, -2.0349e-01,\n",
       "          8.0796e-02, -2.1149e-01,  2.5404e-01,  1.4783e-01,  5.1502e-01,\n",
       "         -9.1678e-02, -2.3147e-02, -4.0319e-01, -3.6959e-01, -2.2916e-01,\n",
       "          4.6185e-01, -3.8822e-01,  7.4077e-02,  2.9953e-01,  2.4333e-01,\n",
       "          5.1495e-02, -2.0837e-01, -3.8860e-01, -9.8624e-02,  2.9719e-01,\n",
       "          4.4946e-01,  2.6239e-01,  2.5784e-01, -2.6172e-01,  2.8332e-01,\n",
       "          2.9093e-02,  1.7574e-01, -3.2803e-02,  9.7539e-02, -3.6254e-01,\n",
       "         -2.7510e-01,  4.3202e-02, -4.2896e-01,  3.1341e-01, -4.5773e-01,\n",
       "         -1.5495e-01,  2.4920e-01, -2.7767e-01, -3.6559e-01,  2.3566e-01,\n",
       "          1.1863e-01,  3.9739e-02,  1.6808e-02, -4.6332e-02,  6.6307e-01,\n",
       "          3.1223e-01, -6.6478e-02, -3.8703e-01, -4.7546e-01,  6.0875e-01,\n",
       "         -8.4124e-02, -1.7053e-01, -6.0313e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pretrained LLMs (sentence transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21577ca1c91e4fa882d7c740bb7cbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer_config.json', max=350.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b07c91857554076ac042fd500d02bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading vocab.txt', max=231508.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16adc5a9d8b44f9f9b82b202d3b2cd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer.json', max=466247.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc4e4c6fbae4f698e9b7dd82e9e8453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)cial_tokens_map.json', max=112.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b76a3f2b6e349dcb1056b815cee98a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading config.json', max=612.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f631faa9d4f4f8591f67b5c36a8c44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading pytorch_model.bin', max=90888945.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings para oraciones usando mean_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
      "          2.6528e-03,  3.9375e-02, -7.0985e-03,  5.9361e-02,  3.1537e-02,\n",
      "          6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
      "          1.1268e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
      "          2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
      "         -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
      "         -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2530e-03,\n",
      "          3.6702e-02, -1.3942e-02,  6.5392e-02, -2.6427e-02,  2.0640e-04,\n",
      "         -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
      "         -8.8409e-02,  2.6243e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
      "         -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
      "          4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
      "          1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
      "         -6.4717e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
      "          2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1957e-04, -8.0297e-02,\n",
      "         -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
      "         -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
      "         -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3188e-03,  4.0234e-03,\n",
      "         -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6085e-02,  1.3062e-02,\n",
      "         -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8751e-02,  1.2001e-01,\n",
      "         -1.0392e-02,  4.8971e-02,  5.5354e-02,  4.4936e-02, -4.0097e-03,\n",
      "         -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
      "         -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7333e-03,  2.7696e-04,\n",
      "         -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5393e-02,\n",
      "          2.4504e-02,  5.9761e-02, -7.3819e-02,  1.1984e-02, -6.6340e-02,\n",
      "         -7.6904e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6079e-02,\n",
      "         -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
      "          1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8106e-03, -1.7029e-02,\n",
      "          2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
      "          1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8909e-02,\n",
      "         -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
      "          2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
      "         -5.9001e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
      "         -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6150e-04, -5.2717e-02,\n",
      "          2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8587e-03,\n",
      "          1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3996e-03,  4.0482e-02,\n",
      "          1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
      "          5.0820e-02, -2.3125e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
      "         -5.6344e-02,  6.2993e-02, -3.1553e-02,  3.2491e-02,  2.3467e-02,\n",
      "         -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
      "         -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6636e-03,\n",
      "         -8.0152e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5080e-01,\n",
      "          3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9321e-03,  4.0053e-02,\n",
      "         -8.7707e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
      "          7.3554e-02,  1.3474e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
      "          5.7836e-02, -9.1899e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
      "          6.1840e-02, -7.6347e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
      "          3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3285e-03,\n",
      "          1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
      "          8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
      "         -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
      "         -7.6898e-02, -4.3186e-02, -1.8998e-02, -2.9166e-02,  5.7749e-02,\n",
      "          2.4182e-02, -1.1690e-02, -6.2144e-02,  2.8435e-02, -2.3752e-04,\n",
      "         -2.5178e-02,  4.3964e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
      "         -3.6552e-02, -7.9375e-02, -5.0853e-03,  6.6970e-02, -1.1778e-01,\n",
      "          3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4845e-02,  8.2495e-03,\n",
      "         -1.0675e-02, -6.8188e-02,  1.1182e-03,  2.4802e-02, -6.3589e-02,\n",
      "          2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
      "         -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
      "          3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9145e-02, -6.3810e-02,\n",
      "         -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
      "         -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5451e-03, -4.1714e-02,\n",
      "         -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
      "         -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
      "         -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
      "          2.0246e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
      "          3.5267e-02,  5.5858e-02, -4.6712e-02,  3.4510e-02,  3.2958e-02,\n",
      "          4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
      "         -5.4791e-02,  2.7752e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
      "         -5.1575e-03,  2.3508e-02,  7.5314e-02,  1.9284e-02,  3.3620e-02,\n",
      "          5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
      "          2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
      "          1.0377e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7653e-03,\n",
      "          3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
      "          7.1691e-03,  4.8468e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
      "          3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
      "         -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02],\n",
      "        [ 8.6439e-02,  1.0276e-01,  5.3945e-03,  2.0444e-03, -9.9634e-03,\n",
      "          2.5386e-02,  4.9288e-02, -3.0627e-02,  6.8725e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4172e-02,\n",
      "          2.8049e-02, -8.6846e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2492e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8524e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1008e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4065e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9067e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3035e-03,  7.5140e-02,  2.4638e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2886e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0368e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0319e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0926e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8774e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3986e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8306e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1452e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4516e-04,  3.4713e-02,  6.2546e-03, -6.9278e-03,  3.9240e-02,\n",
      "          1.1567e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5055e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0867e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0227e-03, -3.9760e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4988e-03,  5.3005e-34, -4.1319e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2178e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2475e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4968e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9493e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8549e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2766e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0947e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0681e-03,  3.1477e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6961e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1359e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8694e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4178e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
